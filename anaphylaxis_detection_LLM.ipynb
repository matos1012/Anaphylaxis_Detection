{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8s8DjGc8FDr"
      },
      "outputs": [],
      "source": [
        "!pip install pandas==1.5.3\n",
        "!pip install openai==0.28.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code processes a CSV file using the GPT-4 API to generate text responses based on specific input data. It reads the CSV file using the `pandas` library and identifies the first empty row in the output column to determine the starting line for processing. It then iterates over a specified range of rows, combines a prompt template with content from a designated column, and calls the GPT-4 API to generate a response. The response is inserted into the output column of the CSV file. The code saves progress periodically and ensures the updated DataFrame is saved back to the CSV file. The main tools used are `pandas` for data manipulation and `openai` for interacting with the GPT-4 API. The objective is to automate the generation of text responses for rows in a CSV file based on input data, facilitating tasks such as text analysis or content generation."
      ],
      "metadata": {
        "id": "4SxA2YmSobBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from openai.error import APIError\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = 'API_KEY'\n",
        "\n",
        "# Function to call GPT-4 using the chat API\n",
        "def callGPT4(message):\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "            messages=[{\"role\": \"user\", \"content\": message}],\n",
        "            temperature=0.0\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except APIError as error:\n",
        "        print(f\"API Error: {error}\")\n",
        "        return None\n",
        "\n",
        "# Function to process CSV using GPT API within a specified line range\n",
        "def process_csv_with_gpt(csv_file_name, prompt_column, output_column, prompt_template, total_lines_to_process):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(csv_file_name)\n",
        "\n",
        "    # Identify the start line based on the first empty row in the output column\n",
        "    start_line = df[output_column].isna().idxmax()\n",
        "    end_line = min(start_line + total_lines_to_process, len(df))\n",
        "\n",
        "    # Iterate over the specified range of rows in the DataFrame\n",
        "    for index, row in df.iloc[start_line:end_line].iterrows():\n",
        "        # Combine the prompt template with the content of the specified column\n",
        "        combined_message = prompt_template.format(content=row[prompt_column])\n",
        "\n",
        "        # Call the GPT-4 chat API\n",
        "        chat_response = callGPT4(combined_message)\n",
        "\n",
        "        # Check for a valid response before updating the DataFrame\n",
        "        if chat_response is not None:\n",
        "            # Insert the response into the specified output column\n",
        "            df.at[index, output_column] = chat_response\n",
        "\n",
        "        # Save periodically after processing every 10 lines\n",
        "        if (index - start_line + 1) % 10 == 0:\n",
        "            df.to_csv(csv_file_name, index=False)\n",
        "            print(f\"Saved progress at line {index}\")\n",
        "\n",
        "    # Save the updated DataFrame back to the same CSV file after processing all lines\n",
        "    df.to_csv(csv_file_name, index=False)\n",
        "    print(\"Processing completed and saved.\")\n",
        "\n",
        "# Example usage\n",
        "process_csv_with_gpt(\n",
        "    csv_file_name='FILE_NAME.csv',\n",
        "    prompt_column='anamnesis',\n",
        "    output_column='AITextoRetornado',\n",
        "    prompt_template=\"\"\"\n",
        "    PART1\n",
        "\n",
        "    {content}\n",
        "\n",
        "    PART2\n",
        "    \"\"\",\n",
        "    total_lines_to_process=20 # Total lines to process this run\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVBsMmoK8Hf3",
        "outputId": "534da01e-f5f3-4524-b35a-37dd211ea6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress at line 9\n",
            "Saved progress at line 19\n",
            "Processing completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping and extract json 1\n",
        "\n",
        "import csv\n",
        "import re\n",
        "\n",
        "# Path to your original CSV file\n",
        "csv_file_path = 'FILE_NAME.csv'\n",
        "\n",
        "# Path to the new CSV file\n",
        "new_csv_file_path = 'FILE_NAME_JSON1.csv'\n",
        "\n",
        "# Reading the original CSV file\n",
        "with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    lines = list(csv_reader)\n",
        "\n",
        "# Mapping from JSON keys to CSV column names\n",
        "json_to_csv_mapping = {\n",
        "    'suspeita': 'AI Anafilaxia',\n",
        "    'alergenico': 'AI Alérgeno',\n",
        "    'raciocinio': 'AI Raciocínio',\n",
        "    'probabilidade': 'AI Probabilidade'\n",
        "}\n",
        "\n",
        "# Processing each line to extract data from the text\n",
        "updated_lines = []\n",
        "for line in lines:\n",
        "    text = line['AITextoRetornado']\n",
        "\n",
        "    # Extracting key-value pairs using regular expressions\n",
        "    # This regex matches both boolean, textual, and numerical values\n",
        "    matches = re.findall(r'\"(\\w+)\":\\s*(true|false|\".+?\"|[\\d,]+(\\.\\d+)?)', text)\n",
        "\n",
        "    # Updating the line with the extracted data\n",
        "    for match in matches:\n",
        "        key = match[0]\n",
        "        value = match[1]\n",
        "        # If the value is a string (enclosed in quotes), remove the quotes\n",
        "        if value.startswith('\"') and value.endswith('\"'):\n",
        "            value = value[1:-1]\n",
        "        csv_key = json_to_csv_mapping.get(key)\n",
        "        if csv_key in line:  # Only update if the key exists as a column\n",
        "            line[csv_key] = value\n",
        "\n",
        "    updated_lines.append(line)\n",
        "\n",
        "# Writing the updated data back to a new CSV file\n",
        "with open(new_csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=csv_reader.fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(updated_lines)"
      ],
      "metadata": {
        "id": "JYiKOEsa8Ywa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code processes a CSV file using the GPT-4 API to generate text responses based on specific input data, conditioned on another column's value, and complements the first code by adding a double validation process. It reads the CSV file using the `pandas` library and identifies the first empty row in the output column to determine the starting line for processing. It then iterates over a specified range of rows, checks if the output column is empty and if a condition in another column is met, combines a prompt template with content from a designated column, and calls the GPT-4 API to generate a response. The response is inserted into the output column of the CSV file. The code saves progress periodically and ensures the updated DataFrame is saved back to the CSV file. The main tools used are `pandas` for data manipulation and `openai` for interacting with the GPT-4 API. The objective is to automate the generation of text responses for rows in a CSV file based on input data, facilitating tasks such as text analysis or content generation while considering specific conditions and performing double validation."
      ],
      "metadata": {
        "id": "Lb1AOZ_hpEEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "from openai.error import APIError\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = 'API_KEY'\n",
        "\n",
        "# Function to call GPT-4 using the chat API\n",
        "def callGPT4(message):\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"user\", \"content\": message}],\n",
        "            temperature=0.0\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except APIError as error:\n",
        "        print(f\"API Error: {error}\")\n",
        "        return None\n",
        "\n",
        "# Function to process CSV using GPT API within a specified line range\n",
        "def process_csv_with_gpt(csv_file_name, prompt_column, output_column, condition_column, prompt_template, total_lines_to_process):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(csv_file_name)\n",
        "\n",
        "    # Identify the start line based on the first empty row in the output column\n",
        "    start_line = df[output_column].isna().idxmax()\n",
        "    end_line = min(start_line + total_lines_to_process, len(df))\n",
        "\n",
        "    # Iterate over the specified range of rows in the DataFrame\n",
        "    for index, row in df.iloc[start_line:end_line].iterrows():\n",
        "        # Check if the output column is empty and if the condition is met\n",
        "        if pd.isna(row[output_column]) and row[condition_column]:\n",
        "            # Combine the prompt template with the content of the specified column\n",
        "            combined_message = prompt_template.format(content=row[prompt_column])\n",
        "\n",
        "            # Call the GPT-4 chat API\n",
        "            chat_response = callGPT4(combined_message)\n",
        "\n",
        "            # Check for a valid response before updating the DataFrame\n",
        "            if chat_response is not None:\n",
        "                # Insert the response into the specified output column\n",
        "                df.at[index, output_column] = chat_response\n",
        "\n",
        "        # Save periodically after processing every 10 lines\n",
        "        if (index - start_line + 1) % 10 == 0:\n",
        "            df.to_csv(csv_file_name, index=False)\n",
        "            print(f\"Saved progress at line {index}\")\n",
        "\n",
        "    # Save the updated DataFrame back to the same CSV file after processing all lines\n",
        "    df.to_csv(csv_file_name, index=False)\n",
        "    print(\"Processing completed and saved.\")\n",
        "\n",
        "# Example usage\n",
        "process_csv_with_gpt(\n",
        "    csv_file_name='FILE_NAME_JSON1.csv',\n",
        "    prompt_column='anamnesis',\n",
        "    output_column='2-AITextoRetornado',\n",
        "    condition_column='AI Anafilaxia',\n",
        "    prompt_template=\"\"\"\n",
        "    Como um médico clínico geral, sua tarefa é examinar textos médicos e determinar se há sinais de anafilaxia no paciente. Esta avaliação é feita com base nos sintomas, sinais vitais e diagnósticos documentados pelos médicos.\n",
        "    Analise o seguinte texto médico:\n",
        "\n",
        "    {content}\n",
        "\n",
        "    Como resultado da sua análise você deve:\n",
        "    1. Informar se você suspeita que o paciente tem anafilaxia.\n",
        "    2. Se você tem uma suspeita, explicar como os critérios 1 ou 2 são satisfeitos (cite trechos do texto). Se não, citar quais aspectos dos critérios 1 e 2 estão faltando.\n",
        "    3. Represente, com um número de 0 a 1, a probabilidade do paciente ter anafilaxia, em sua opinião.\n",
        "    Lembre de fazer a sua análise passo a passo.\n",
        "\n",
        "    Baseando-se em sua análise, produza também um objeto JSON com as chaves:\n",
        "\n",
        "    - \"suspeita\": com valor \"true\" se existe uma suspeita de anafilaxia ou \"false\" se não.\n",
        "    - \"raciocinio\": explicação de seu raciocínio para concluir a suspeita ou ausência da anafilaxia.\n",
        "    - \"alergenico\": a substância alergênica, se ela for identificada, ou a sentença 'Não identificado'.\n",
        "    - \"probabilidade\": um valor de 0 a 1 indicando a probabilidade de ser anafilaxia, em sua opinião.\n",
        "\n",
        "    Prossiga cuidadosamente.\n",
        "    \"\"\",\n",
        "    total_lines_to_process=10 # Total lines to process this run\n",
        ")\n"
      ],
      "metadata": {
        "id": "yQNKlHYR87H8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec2b34f-4438-4e79-9133-271b46f18e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress at line 19\n",
            "Processing completed and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping and extract json 2\n",
        "\n",
        "import csv\n",
        "import re\n",
        "\n",
        "# Path to your original CSV file\n",
        "csv_file_path = 'FILE_NAME_JSON1.csv'\n",
        "\n",
        "# Path to the new CSV file\n",
        "new_csv_file_path = 'FILE_NAME_JSON2.csv'\n",
        "\n",
        "# Reading the original CSV file\n",
        "with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    lines = list(csv_reader)\n",
        "\n",
        "# Mapping from JSON keys to CSV column names\n",
        "json_to_csv_mapping = {\n",
        "    'alergenico': '2-AI Alérgeno',\n",
        "    'raciocinio': '2-AI Raciocínio',\n",
        "    'suspeita': '2- AI Anafilaxia',\n",
        "    'probabilidade': '2-AI Probabilidade'\n",
        "}\n",
        "\n",
        "# Processing each line to extract data from the text\n",
        "updated_lines = []\n",
        "for line in lines:\n",
        "    text = line['2-AITextoRetornado']\n",
        "\n",
        "    # Adjusting the regex to better capture boolean values\n",
        "    matches = re.findall(r'\"(\\w+)\":\\s*(true|false|\".*?\"|\\d+(\\.\\d+)?)', text)\n",
        "\n",
        "    # Debugging: Print matches to see what is being extracted\n",
        "    print(f\"Matches for line: {matches}\")\n",
        "\n",
        "    # Updating the line with the extracted data\n",
        "    for match in matches:\n",
        "        key, value = match[0], match[1]\n",
        "        if value.startswith('\"') and value.endswith('\"'):\n",
        "            value = value[1:-1]  # Remove quotes if the value is a string\n",
        "        csv_key = json_to_csv_mapping.get(key)\n",
        "        if csv_key in line:  # Only update if the key exists as a column\n",
        "            line[csv_key] = value\n",
        "\n",
        "    updated_lines.append(line)\n",
        "\n",
        "# Writing the updated data back to a new CSV file\n",
        "with open(new_csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=csv_reader.fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(updated_lines)"
      ],
      "metadata": {
        "id": "N10R08iP9NnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorization 1\n",
        "\n",
        "import csv\n",
        "\n",
        "# Path to your original CSV file\n",
        "csv_file_path = 'FILE_NAME_JSON2.csv'\n",
        "\n",
        "# Path to the new CSV file\n",
        "new_csv_file_path = 'FILE_NAME_CATEGORIZED.csv'\n",
        "\n",
        "# Reading the original CSV file\n",
        "with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    lines = list(csv_reader)\n",
        "\n",
        "    # Check if 'categorizacao' column already exists\n",
        "    if 'categorizacao' not in csv_reader.fieldnames:\n",
        "        csv_reader.fieldnames.append('categorizacao')\n",
        "\n",
        "# Adding the 'categorizacao' column and performing categorization\n",
        "for line in lines:\n",
        "    anafilaxia = line['Anafilaxia'].lower()\n",
        "    ai_anafilaxia = line['AI Anafilaxia'].lower()\n",
        "\n",
        "    # Convert 'verdadeiro' and 'falso' to 'true' and 'false'\n",
        "    anafilaxia = 'true' if anafilaxia in ['true', 'verdadeiro'] else 'false'\n",
        "    ai_anafilaxia = 'true' if ai_anafilaxia in ['true', 'verdadeiro'] else 'false'\n",
        "\n",
        "    if ai_anafilaxia not in ['true', 'false']:\n",
        "        line['categorizacao'] = 'Erro'\n",
        "    else:\n",
        "        if anafilaxia == 'true' and ai_anafilaxia == 'true':\n",
        "            line['categorizacao'] = 'TP'\n",
        "        elif anafilaxia == 'false' and ai_anafilaxia == 'false':\n",
        "            line['categorizacao'] = 'TN'\n",
        "        elif anafilaxia == 'false' and ai_anafilaxia == 'true':\n",
        "            line['categorizacao'] = 'FP'\n",
        "        elif anafilaxia == 'true' and ai_anafilaxia == 'false':\n",
        "            line['categorizacao'] = 'FN'\n",
        "\n",
        "    # Marking rows with empty 'AI Anafilaxia' as 'Erro'\n",
        "    if not line['AI Anafilaxia'].strip():\n",
        "        line['categorizacao'] = 'Erro'\n",
        "\n",
        "# Writing the updated data back to a new CSV file\n",
        "with open(new_csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=csv_reader.fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(lines)\n",
        "\n"
      ],
      "metadata": {
        "id": "xIa7GBVA9UKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorization 2\n",
        "\n",
        "import csv\n",
        "\n",
        "# Path to your original CSV file\n",
        "csv_file_path = 'FILE_NAME_CATEGORIZED.csv'\n",
        "\n",
        "# Path to the new CSV file\n",
        "new_csv_file_path = 'FILE_NAME_CATEGORIZED2.csv'\n",
        "\n",
        "# Reading the original CSV file\n",
        "with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    lines = list(csv_reader)\n",
        "\n",
        "    # Check if '2-categorizacao' column already exists\n",
        "    if '2-categorizacao' not in csv_reader.fieldnames:\n",
        "        csv_reader.fieldnames.append('2-categorizacao')\n",
        "\n",
        "# Performing categorization\n",
        "for line in lines:\n",
        "    anafilaxia = line['Anafilaxia'].strip().lower()\n",
        "    ai_anafilaxia = line.get('2- AI Anafilaxia', '').strip().lower()\n",
        "\n",
        "    # If '2-AI Anafilaxia' is empty, copy the value from 'categorizacao' to '2-categorizacao'\n",
        "    if not ai_anafilaxia:\n",
        "        line['2-categorizacao'] = line['categorizacao']\n",
        "    else:\n",
        "        # Determine the correct categorization based on 'Anafilaxia' and '2-AI Anafilaxia'\n",
        "        if anafilaxia == 'true' and ai_anafilaxia == 'true':\n",
        "            line['2-categorizacao'] = 'TP'\n",
        "        elif anafilaxia == 'false' and ai_anafilaxia == 'false':\n",
        "            line['2-categorizacao'] = 'TN'\n",
        "        elif anafilaxia == 'false' and ai_anafilaxia == 'true':\n",
        "            line['2-categorizacao'] = 'FP'\n",
        "        elif anafilaxia == 'true' and ai_anafilaxia == 'false':\n",
        "            line['2-categorizacao'] = 'FN'\n",
        "\n",
        "# Writing the updated data back to a new CSV file\n",
        "with open(new_csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=csv_reader.fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(lines)\n"
      ],
      "metadata": {
        "id": "3DM71lZv9VfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Path to your original CSV file\n",
        "csv_file_path = 'FILE_NAME_JSON2.csv'\n",
        "\n",
        "# Path to the final CSV file\n",
        "final_csv_file_path = 'FILE_NAME_CATEGORIZED.csv'\n",
        "\n",
        "# Reading the original CSV file\n",
        "with open(csv_file_path, mode='r', encoding='utf-8') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "    lines = list(csv_reader)\n",
        "\n",
        "    # Check if 'categorizacao' and '2-categorizacao' columns already exist\n",
        "    if 'categorizacao' not in csv_reader.fieldnames:\n",
        "        csv_reader.fieldnames.append('categorizacao')\n",
        "    if '2-categorizacao' not in csv_reader.fieldnames:\n",
        "        csv_reader.fieldnames.append('2-categorizacao')\n",
        "\n",
        "# Adding the 'categorizacao' column and performing the first categorization\n",
        "for line in lines:\n",
        "    anafilaxia = line['Anafilaxia'].lower()\n",
        "    ai_anafilaxia = line['AI Anafilaxia'].lower()\n",
        "\n",
        "    # Convert 'verdadeiro' and 'falso' to 'true' and 'false'\n",
        "    anafilaxia = 'true' if anafilaxia in ['true', 'verdadeiro'] else 'false'\n",
        "    ai_anafilaxia = 'true' if ai_anafilaxia in ['true', 'verdadeiro'] else 'false'\n",
        "\n",
        "    if ai_anafilaxia not in ['true', 'false']:\n",
        "        line['categorizacao'] = 'Erro'\n",
        "    else:\n",
        "        if anafilaxia == 'true' and ai_anafilaxia == 'true':\n",
        "            line['categorizacao'] = 'TP'\n",
        "        elif anafilaxia == 'false' and ai_anafilaxia == 'false':\n",
        "            line['categorizacao'] = 'TN'\n",
        "        elif anafilaxia == 'false' and ai_anafilaxia == 'true':\n",
        "            line['categorizacao'] = 'FP'\n",
        "        elif anafilaxia == 'true' and ai_anafilaxia == 'false':\n",
        "            line['categorizacao'] = 'FN'\n",
        "\n",
        "    # Marking rows with empty 'AI Anafilaxia' as 'Erro'\n",
        "    if not line['AI Anafilaxia'].strip():\n",
        "        line['categorizacao'] = 'Erro'\n",
        "\n",
        "# Performing the second categorization and adding the '2-categorizacao' column\n",
        "for line in lines:\n",
        "    anafilaxia = line['Anafilaxia'].strip().lower()\n",
        "    ai_anafilaxia = line.get('2- AI Anafilaxia', '').strip().lower()\n",
        "\n",
        "    # If '2-AI Anafilaxia' is empty, copy the value from 'categorizacao' to '2-categorizacao'\n",
        "    if not ai_anafilaxia:\n",
        "        line['2-categorizacao'] = line['categorizacao']\n",
        "    else:\n",
        "        # Determine the correct categorization based on 'Anafilaxia' and '2-AI Anafilaxia'\n",
        "        if anafilaxia == 'true' and ai_anafilaxia == 'true':\n",
        "            line['2-categorizacao'] = 'TP'\n",
        "        elif anafilaxia == 'false' and ai_anafilaxia == 'false':\n",
        "            line['2-categorizacao'] = 'TN'\n",
        "        elif anafilaxia == 'false' and ai_anafilaxia == 'true':\n",
        "            line['2-categorizacao'] = 'FP'\n",
        "        elif anafilaxia == 'true' and ai_anafilaxia == 'false':\n",
        "            line['2-categorizacao'] = 'FN'\n",
        "\n",
        "# Writing the updated data back to a new CSV file\n",
        "with open(final_csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=csv_reader.fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(lines)\n"
      ],
      "metadata": {
        "id": "c1zsPB0xrdHr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}